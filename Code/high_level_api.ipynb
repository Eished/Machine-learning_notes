{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.vision as vision\n",
    "import paddle.text as text\n",
    "\n",
    "paddle.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视觉相关数据集： ['DatasetFolder', 'ImageFolder', 'MNIST', 'FashionMNIST', 'Flowers', 'Cifar10', 'Cifar100', 'VOC2012']\n",
      "自然语言相关数据集： ['Conll05st', 'Imdb', 'Imikolov', 'Movielens', 'UCIHousing', 'WMT14', 'WMT16', 'ViterbiDecoder', 'viterbi_decode']\n"
     ]
    }
   ],
   "source": [
    "print('视觉相关数据集：', paddle.vision.datasets.__all__)\n",
    "print('自然语言相关数据集：', paddle.text.__all__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle.vision.transforms import ToTensor\n",
    "# 训练数据集\n",
    "train_dataset = vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "\n",
    "# 验证数据集\n",
    "val_dataset = vision.datasets.MNIST(mode='test', transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============train dataset=============\n",
      "traindata1 label1\n",
      "traindata2 label2\n",
      "traindata3 label3\n",
      "traindata4 label4\n",
      "=============evaluation dataset=============\n",
      "testdata1 label1\n",
      "testdata2 label2\n",
      "testdata3 label3\n",
      "testdata4 label4\n"
     ]
    }
   ],
   "source": [
    "from paddle.io import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承paddle.io.Dataset类\n",
    "    \"\"\"\n",
    "    def __init__(self, mode='train'):\n",
    "        \"\"\"\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练和测试数据集\n",
    "        \"\"\"\n",
    "        super(MyDataset, self).__init__()\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.data = [\n",
    "                ['traindata1', 'label1'],\n",
    "                ['traindata2', 'label2'],\n",
    "                ['traindata3', 'label3'],\n",
    "                ['traindata4', 'label4'],\n",
    "            ]\n",
    "        else:\n",
    "            self.data = [\n",
    "                ['testdata1', 'label1'],\n",
    "                ['testdata2', 'label2'],\n",
    "                ['testdata3', 'label3'],\n",
    "                ['testdata4', 'label4'],\n",
    "            ]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）\n",
    "        \"\"\"\n",
    "        data = self.data[index][0]\n",
    "        label = self.data[index][1]\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四：实现__len__方法，返回数据集总数目\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "# 测试定义的数据集\n",
    "train_dataset_2 = MyDataset(mode='train')\n",
    "val_dataset_2 = MyDataset(mode='test')\n",
    "\n",
    "print('=============train dataset=============')\n",
    "for data, label in train_dataset_2:\n",
    "    print(data, label)\n",
    "\n",
    "print('=============evaluation dataset=============')\n",
    "for data, label in val_dataset_2:\n",
    "    print(data, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle.vision.transforms import Compose, Resize, ColorJitter\n",
    "\n",
    "# 定义想要使用那些数据增强方式，这里用到了随机调整亮度、对比度和饱和度，改变图片大小\n",
    "transform = Compose([ColorJitter(), Resize(size=100)])\n",
    "\n",
    "# 通过transform参数传递定义好的数据增项方法即可完成对自带数据集的应用\n",
    "train_dataset_3 = vision.datasets.MNIST(mode='train', transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle.io import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, mode='train'):\n",
    "        super(MyDataset, self).__init__()\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.data = [\n",
    "                ['traindata1', 'label1'],\n",
    "                ['traindata2', 'label2'],\n",
    "                ['traindata3', 'label3'],\n",
    "                ['traindata4', 'label4'],\n",
    "            ]\n",
    "        else:\n",
    "            self.data = [\n",
    "                ['testdata1', 'label1'],\n",
    "                ['testdata2', 'label2'],\n",
    "                ['testdata3', 'label3'],\n",
    "                ['testdata4', 'label4'],\n",
    "            ]\n",
    "\n",
    "        # 定义要使用的数据预处理方法，针对图片的操作\n",
    "        self.transform = Compose([ColorJitter(), Resize(size=100)])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index][0]\n",
    "\n",
    "        # 在这里对训练数据进行应用\n",
    "        # 这里只是一个示例，测试时需要将数据集更换为图片数据进行测试\n",
    "        data = self.transform(data)\n",
    "\n",
    "        label = self.data[index][1]\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential形式组网\n",
    "mnist = paddle.nn.Sequential(\n",
    "    paddle.nn.Flatten(),\n",
    "    paddle.nn.Linear(784, 512),\n",
    "    paddle.nn.ReLU(),\n",
    "    paddle.nn.Dropout(0.2),\n",
    "    paddle.nn.Linear(512, 10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer类继承方式组网\n",
    "class Mnist(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Mnist, self).__init__()\n",
    "\n",
    "        self.flatten = paddle.nn.Flatten()\n",
    "        self.linear_1 = paddle.nn.Linear(784, 512)\n",
    "        self.linear_2 = paddle.nn.Linear(512, 10)\n",
    "        self.relu = paddle.nn.ReLU()\n",
    "        self.dropout = paddle.nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = self.flatten(inputs)\n",
    "        y = self.linear_1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.dropout(y)\n",
    "        y = self.linear_2(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "mnist_2 = Mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用GPU训练\n",
    "# paddle.set_device('gpu')\n",
    "\n",
    "# 模型封装\n",
    "\n",
    "## 场景1：动态图模式\n",
    "## 1.1 为模型预测部署场景进行模型训练\n",
    "## 需要添加input和label数据描述，否则会导致使用model.save(training=False)保存的预测模型在使用时出错\n",
    "inputs = paddle.static.InputSpec([-1, 1, 28, 28], dtype='float32', name='input')\n",
    "label = paddle.static.InputSpec([-1, 1], dtype='int8', name='label')\n",
    "model = paddle.Model(mnist, inputs, label)\n",
    "\n",
    "## 1.2 面向实验而进行的模型训练\n",
    "## 可以不传递input和label信息\n",
    "# model = paddle.Model(mnist)\n",
    "\n",
    "## 场景2：静态图模式\n",
    "# paddle.enable_static()\n",
    "# paddle.set_device('gpu')\n",
    "# input = paddle.static.InputSpec([None, 1, 28, 28], dtype='float32')\n",
    "# label = paddle.static.InputSpec([None, 1], dtype='int8')\n",
    "# model = paddle.Model(mnist, input, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Flatten-2       [[1, 28, 28]]           [1, 784]              0       \n",
      "   Linear-3          [[1, 784]]            [1, 512]           401,920    \n",
      "    ReLU-2           [[1, 512]]            [1, 512]              0       \n",
      "   Dropout-2         [[1, 512]]            [1, 512]              0       \n",
      "   Linear-4          [[1, 512]]            [1, 10]             5,130     \n",
      "===========================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 1.55\n",
      "Estimated Total Size (MB): 1.57\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 407050, 'trainable_params': 407050}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary((1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Flatten-2       [[1, 28, 28]]           [1, 784]              0       \n",
      "   Linear-3          [[1, 784]]            [1, 512]           401,920    \n",
      "    ReLU-2           [[1, 512]]            [1, 512]              0       \n",
      "   Dropout-2         [[1, 512]]            [1, 512]              0       \n",
      "   Linear-4          [[1, 512]]            [1, 10]             5,130     \n",
      "===========================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 1.55\n",
      "Estimated Total Size (MB): 1.57\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 407050, 'trainable_params': 407050}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddle.summary(mnist, (1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为模型训练做准备，设置优化器，损失函数和精度计算方式\n",
    "model.prepare(paddle.optimizer.Adam(parameters=model.parameters()), \n",
    "              paddle.nn.CrossEntropyLoss(),\n",
    "              paddle.metric.Accuracy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eis/anaconda3/envs/paddle_env/lib/python3.10/site-packages/paddle/fluid/dygraph/amp/auto_cast.py:328: UserWarning: For float16, amp only support NVIDIA GPU with Compute Capability 7.0 or higher, current GPU is: NVIDIA GeForce GTX 965M, with Compute Capability: 5.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "(External) CUDA error(98), invalid device function. \n  [Hint: Please search for the error code(98) on website (https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3f51e3575c2178246db0a94a430e0038) to get Nvidia's official solution and advice about CUDA Error.] (at /paddle/paddle/phi/kernels/gpu/argsort_kernel.cu:166)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_dataset, \n\u001b[1;32m      3\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, \n\u001b[1;32m      4\u001b[0m           batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m           verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/paddle_env/lib/python3.10/site-packages/paddle/hapi/model.py:1929\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, train_data, eval_data, batch_size, epochs, eval_freq, log_freq, save_dir, save_freq, verbose, drop_last, shuffle, num_workers, callbacks, accumulate_grad_batches, num_iters)\u001b[0m\n\u001b[1;32m   1927\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m   1928\u001b[0m     cbks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m-> 1929\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_one_epoch(train_loader, cbks, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m   1930\u001b[0m     cbks\u001b[39m.\u001b[39mon_epoch_end(epoch, logs)\n\u001b[1;32m   1932\u001b[0m     \u001b[39mif\u001b[39;00m do_eval \u001b[39mand\u001b[39;00m epoch \u001b[39m%\u001b[39m eval_freq \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/paddle_env/lib/python3.10/site-packages/paddle/hapi/model.py:2282\u001b[0m, in \u001b[0;36mModel._run_one_epoch\u001b[0;34m(self, data_loader, callbacks, mode, logs)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   2277\u001b[0m     _inputs\u001b[39m.\u001b[39mappend(\n\u001b[1;32m   2278\u001b[0m         (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accumulate \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   2279\u001b[0m         \u001b[39mor\u001b[39;00m step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(data_loader)\n\u001b[1;32m   2280\u001b[0m     )\n\u001b[0;32m-> 2282\u001b[0m outs \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, mode \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_batch\u001b[39;49m\u001b[39m'\u001b[39;49m)(\u001b[39m*\u001b[39;49m_inputs)\n\u001b[1;32m   2284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metrics \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss:\n\u001b[1;32m   2285\u001b[0m     metrics \u001b[39m=\u001b[39m [[l[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m outs[\u001b[39m0\u001b[39m]]]\n",
      "File \u001b[0;32m~/anaconda3/envs/paddle_env/lib/python3.10/site-packages/paddle/hapi/model.py:1207\u001b[0m, in \u001b[0;36mModel.train_batch\u001b[0;34m(self, inputs, labels, update)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_batch\u001b[39m(\u001b[39mself\u001b[39m, inputs, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, update\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1158\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \n\u001b[1;32m   1160\u001b[0m \u001b[39m    Run one training step on one batch of data. And using `update` indicates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \n\u001b[1;32m   1206\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_adapter\u001b[39m.\u001b[39;49mtrain_batch(inputs, labels, update)\n\u001b[1;32m   1208\u001b[0m     \u001b[39mif\u001b[39;00m fluid\u001b[39m.\u001b[39m_non_static_mode() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_info \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1209\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inputs()\n",
      "File \u001b[0;32m~/anaconda3/envs/paddle_env/lib/python3.10/site-packages/paddle/hapi/model.py:826\u001b[0m, in \u001b[0;36mDynamicGraphAdapter.train_batch\u001b[0;34m(self, inputs, labels, update)\u001b[0m\n\u001b[1;32m    824\u001b[0m metrics \u001b[39m=\u001b[39m []\n\u001b[1;32m    825\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m_metrics:\n\u001b[0;32m--> 826\u001b[0m     metric_outs \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39;49mcompute(\u001b[39m*\u001b[39;49m(to_list(outputs) \u001b[39m+\u001b[39;49m labels))\n\u001b[1;32m    827\u001b[0m     m \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39m[to_numpy(m) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m to_list(metric_outs)])\n\u001b[1;32m    828\u001b[0m     metrics\u001b[39m.\u001b[39mappend(m)\n",
      "File \u001b[0;32m~/anaconda3/envs/paddle_env/lib/python3.10/site-packages/paddle/metric/metrics.py:261\u001b[0m, in \u001b[0;36mAccuracy.compute\u001b[0;34m(self, pred, label, *args)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, pred, label, \u001b[39m*\u001b[39margs):\n\u001b[1;32m    248\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m    Compute the top-k (maximum value in `topk`) indices.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39m        Tensor: Correct mask, a tensor with shape [batch_size, d0, ..., topk].\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     pred \u001b[39m=\u001b[39m paddle\u001b[39m.\u001b[39;49margsort(pred, descending\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    262\u001b[0m     pred \u001b[39m=\u001b[39m paddle\u001b[39m.\u001b[39mslice(pred,\n\u001b[1;32m    263\u001b[0m                         axes\u001b[39m=\u001b[39m[\u001b[39mlen\u001b[39m(pred\u001b[39m.\u001b[39mshape) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m],\n\u001b[1;32m    264\u001b[0m                         starts\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m],\n\u001b[1;32m    265\u001b[0m                         ends\u001b[39m=\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxk])\n\u001b[1;32m    266\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(label\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mor\u001b[39;00m \\\n\u001b[1;32m    267\u001b[0m        (\u001b[39mlen\u001b[39m(label\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m label\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    268\u001b[0m         \u001b[39m# In static mode, the real label data shape may be different\u001b[39;00m\n\u001b[1;32m    269\u001b[0m         \u001b[39m# from shape defined by paddle.static.InputSpec in model\u001b[39;00m\n\u001b[1;32m    270\u001b[0m         \u001b[39m# building, reshape to the right shape.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/paddle_env/lib/python3.10/site-packages/paddle/tensor/search.py:96\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(x, axis, descending, name)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mSorts the input along the given axis, and returns the corresponding index tensor for the sorted output values. The default sort algorithm is ascending, if you want the sort algorithm to be descending, you must set the :attr:`descending` as True.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m        #  [0 2 1 1]]]\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m in_dygraph_mode():\n\u001b[0;32m---> 96\u001b[0m     _, ids \u001b[39m=\u001b[39m _C_ops\u001b[39m.\u001b[39;49margsort(x, axis, descending)\n\u001b[1;32m     97\u001b[0m     \u001b[39mreturn\u001b[39;00m ids\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m _in_legacy_dygraph():\n",
      "\u001b[0;31mOSError\u001b[0m: (External) CUDA error(98), invalid device function. \n  [Hint: Please search for the error code(98) on website (https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3f51e3575c2178246db0a94a430e0038) to get Nvidia's official solution and advice about CUDA Error.] (at /paddle/paddle/phi/kernels/gpu/argsort_kernel.cu:166)\n"
     ]
    }
   ],
   "source": [
    "# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\n",
    "model.fit(train_dataset, \n",
    "          epochs=5, \n",
    "          batch_size=64,\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
