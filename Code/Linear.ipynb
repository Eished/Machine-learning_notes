{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "Tensor(shape=[2, 4], dtype=float32, place=Place(cpu), stop_gradient=False,\n",
      "       [[0.50000000, 0.50000000, 0.50000000, 0.50000000],\n",
      "        [0.50000000, 0.50000000, 0.50000000, 0.50000000]])\n",
      "Parameter containing:\n",
      "Tensor(shape=[4], dtype=float32, place=Place(cpu), stop_gradient=False,\n",
      "       [1., 1., 1., 1.])\n",
      "Tensor(shape=[3, 2], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       [[ 0.39658180, -0.69657004],\n",
      "        [-0.33478394,  1.94147193],\n",
      "        [-0.00060682,  0.55379170]])\n",
      "Tensor(shape=[3, 4], dtype=float32, place=Place(cpu), stop_gradient=False,\n",
      "       [[0.85000587, 0.85000587, 0.85000587, 0.85000587],\n",
      "        [1.80334401, 1.80334401, 1.80334401, 1.80334401],\n",
      "        [1.27659249, 1.27659249, 1.27659249, 1.27659249]])\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import torch\n",
    "\n",
    "device = \"cpu\"\n",
    "paddle.set_device(\"gpu\" if device == \"cuda\" else \"cpu\")\n",
    "\n",
    "paddle.set_grad_enabled(False)\n",
    "\n",
    "# Define the linear layer.\n",
    "weight_attr = paddle.ParamAttr(\n",
    "    name=\"weight\",\n",
    "    initializer=paddle.nn.initializer.Constant(value=0.5))\n",
    "bias_attr = paddle.ParamAttr(\n",
    "    name=\"bias\",\n",
    "    initializer=paddle.nn.initializer.Constant(value=1.0))\n",
    "linear = paddle.nn.Linear(2, 4, weight_attr=weight_attr, bias_attr=bias_attr)\n",
    "print(linear.weight)\n",
    "print(linear.bias)\n",
    "# linear.weight: [[0.5 0.5 0.5 0.5]\n",
    "#                 [0.5 0.5 0.5 0.5]]\n",
    "# linear.bias: [1. 1. 1. 1.]\n",
    "\n",
    "x = paddle.randn((3, 2), dtype=\"float32\")\n",
    "print(x)\n",
    "# x: [[-0.32342386 -1.200079  ]\n",
    "#     [ 0.7979031  -0.90978354]\n",
    "#     [ 0.40597573  1.8095392 ]]\n",
    "y = linear(x)\n",
    "print(y)\n",
    "# y: [[0.23824859 0.23824859 0.23824859 0.23824859]\n",
    "#     [0.9440598  0.9440598  0.9440598  0.9440598 ]\n",
    "#     [2.1077576  2.1077576  2.1077576  2.1077576 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "Tensor(shape=[2, 4], dtype=float64, place=Place(gpu:0), stop_gradient=False,\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "Tensor(shape=[4], dtype=float64, place=Place(gpu:0), stop_gradient=False,\n",
      "       [0., 0., 0., 0.])\n",
      "Tensor(shape=[3, 2], dtype=float64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Tensor(shape=[3, 4], dtype=float64, place=Place(gpu:0), stop_gradient=False,\n",
      "       [[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "device = \"cuda\"\n",
    "paddle.set_device(\"gpu\" if device == \"cuda\" else \"cpu\")\n",
    "paddle.set_default_dtype(\"float64\")\n",
    "paddle.set_grad_enabled(False)\n",
    "\n",
    "# Define the linear layer.\n",
    "weight_attr = paddle.ParamAttr(\n",
    "    name=\"weight\",\n",
    "    initializer=paddle.nn.initializer.Constant(value=0.5))\n",
    "bias_attr = paddle.ParamAttr(\n",
    "    name=\"bias\",\n",
    "    initializer=paddle.nn.initializer.Constant(value=1.0))\n",
    "linear = paddle.nn.Linear(2, 4)\n",
    "print(linear.weight)\n",
    "print(linear.bias)\n",
    "# linear.weight: [[0.5 0.5 0.5 0.5]\n",
    "#                 [0.5 0.5 0.5 0.5]]\n",
    "# linear.bias: [1. 1. 1. 1.]\n",
    "\n",
    "x = paddle.randn((3, 2), dtype=\"float64\")\n",
    "print(x)\n",
    "# x: [[-0.32342386 -1.200079  ]\n",
    "#     [ 0.7979031  -0.90978354]\n",
    "#     [ 0.40597573  1.8095392 ]]\n",
    "y = linear(x)\n",
    "print(y)\n",
    "# y: [[0.23824859 0.23824859 0.23824859 0.23824859]\n",
    "#     [0.9440598  0.9440598  0.9440598  0.9440598 ]\n",
    "#     [2.1077576  2.1077576  2.1077576  2.1077576 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用forward方法。\n",
      "abs max: 0.0\n",
      "abs mean: 0.0\n",
      "isclose: True\n",
      "paddle matmul与torch matmul对比\n",
      "abs max: 0.0\n",
      "abs mean: 0.0\n",
      "isclose: True\n",
      "paddle forward与paddle matmul对比\n",
      "abs max: 0.0\n",
      "abs mean: 0.0\n",
      "isclose: True\n",
      "paddle forward与torch matmul对比\n",
      "abs max: 0.0\n",
      "abs mean: 0.0\n",
      "isclose: True\n",
      "torch forward与torch matmul对比\n",
      "abs max: 0.0\n",
      "abs mean: 0.0\n",
      "isclose: True\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import torch\n",
    "import numpy as np\n",
    "# 这是cpu环境下。修改成gpu再试试\n",
    "\n",
    "device = \"cuda\"\n",
    "paddle.set_device(\"gpu\" if device == \"cuda\" else \"cpu\")\n",
    "\n",
    "paddle.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# 定义模型\n",
    "paddle_linear = paddle.nn.Linear(768, 768)\n",
    "paddle_linear.eval()\n",
    "paddle_linear.weight.set_value(paddle.randn(paddle_linear.weight.shape))\n",
    "paddle_linear.bias.set_value(paddle.randn(paddle_linear.bias.shape))\n",
    "# 定义模型\n",
    "torch_linear = torch.nn.Linear(768, 768)\n",
    "torch_linear.eval()\n",
    "torch_linear.weight.data = torch.tensor(paddle_linear.weight.t().numpy())\n",
    "torch_linear.bias.data = torch.tensor(paddle_linear.bias.numpy())\n",
    "torch_linear.to(device)\n",
    "# 定义输入\n",
    "paddle_inputs = paddle.randn((32, 768)) * 10\n",
    "torch_inputs = torch.tensor(paddle_inputs.numpy()).to(device)\n",
    "\n",
    "# 前向输出\n",
    "paddle_outputs = paddle_linear(paddle_inputs).numpy()\n",
    "torch_outputs = torch_linear(torch_inputs).cpu().numpy()\n",
    "\n",
    "print(\"使用forward方法。\")\n",
    "print(\"abs max:\", np.abs(paddle_outputs-torch_outputs).max())\n",
    "print(\"abs mean:\", np.abs(paddle_outputs-torch_outputs).mean())\n",
    "print(\"isclose:\", np.all(np.isclose(paddle_outputs, torch_outputs, atol=0, rtol=1.e-6)))\n",
    "\n",
    "# paddle matmul与torch matmul对比\n",
    "print(\"paddle matmul与torch matmul对比\")\n",
    "paddle_shougong_outputs = (paddle.matmul(\n",
    "    paddle_inputs, paddle_linear.weight) + paddle_linear.bias).numpy()\n",
    "torch_shougong_outputs = (torch.matmul(\n",
    "    torch_inputs, torch_linear.weight.t()) + torch_linear.bias).cpu().numpy()\n",
    "print(\"abs max:\", np.abs(paddle_shougong_outputs-torch_shougong_outputs).max())\n",
    "print(\"abs mean:\", np.abs(paddle_shougong_outputs-torch_shougong_outputs).mean())\n",
    "print(\"isclose:\", np.all(np.isclose(paddle_shougong_outputs,\n",
    "      torch_shougong_outputs, atol=0, rtol=1.e-6)))\n",
    "\n",
    "\n",
    "# paddle forward与paddle matmul对比\n",
    "print(\"paddle forward与paddle matmul对比\")\n",
    "print(\"abs max:\", np.abs(paddle_shougong_outputs-paddle_outputs).max())\n",
    "print(\"abs mean:\", np.abs(paddle_shougong_outputs-paddle_outputs).mean())\n",
    "print(\"isclose:\", np.all(np.isclose(\n",
    "    paddle_shougong_outputs, paddle_outputs, atol=0, rtol=1.e-6)))\n",
    "\n",
    "\n",
    "# paddle forward与torch matmul对比\n",
    "print(\"paddle forward与torch matmul对比\")\n",
    "print(\"abs max:\", np.abs(paddle_outputs-torch_shougong_outputs).max())\n",
    "print(\"abs mean:\", np.abs(paddle_outputs-torch_shougong_outputs).mean())\n",
    "print(\"isclose:\", np.all(np.isclose(paddle_outputs,\n",
    "      torch_shougong_outputs, atol=0, rtol=1.e-6)))\n",
    "\n",
    "# torch forward与torch matmul对比\n",
    "print(\"torch forward与torch matmul对比\")\n",
    "print(\"abs max:\", np.abs(torch_outputs-torch_shougong_outputs).max())\n",
    "print(\"abs mean:\", np.abs(torch_outputs-torch_shougong_outputs).mean())\n",
    "print(\"isclose:\", np.all(np.isclose(torch_outputs,\n",
    "      torch_shougong_outputs, atol=0, rtol=1.e-6)))\n",
    "\n",
    "# 输出\n",
    "# cpu条件下\n",
    "# 使用forward方法。\n",
    "# abs max: 0.00012207031\n",
    "# abs mean: 7.5253715e-06\n",
    "# isclose: False\n",
    "# paddle matmul与torch matmul对比\n",
    "# abs max: 0.0\n",
    "# abs mean: 0.0\n",
    "# isclose: True\n",
    "# paddle forward与paddle matmul对比\n",
    "# abs max: 0.0\n",
    "# abs mean: 0.0\n",
    "# isclose: True\n",
    "# paddle forward与torch matmul对比\n",
    "# abs max: 0.0\n",
    "# abs mean: 0.0\n",
    "# isclose: True\n",
    "# torch forward与torch matmul对比\n",
    "# abs max: 0.00012207031\n",
    "# abs mean: 7.5253715e-06\n",
    "# isclose: False\n",
    "\n",
    "# gpu条件下（RTX2060）\n",
    "# 使用forward方法。\n",
    "# abs max: 0.0\n",
    "# abs mean: 0.0\n",
    "# isclose: True\n",
    "# paddle matmul与torch matmul对比\n",
    "# abs max: 0.0\n",
    "# abs mean: 0.0\n",
    "# isclose: True\n",
    "# paddle forward与paddle matmul对比\n",
    "# abs max: 0.0\n",
    "# abs mean: 0.0\n",
    "# isclose: True\n",
    "# paddle forward与torch matmul对比\n",
    "# abs max: 0.0\n",
    "# abs mean: 0.0\n",
    "# isclose: True\n",
    "# torch forward与torch matmul对比\n",
    "# abs max: 0.0\n",
    "# abs mean: 0.0\n",
    "# isclose: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([1.2060, 0.2744, 0.5401])\n",
      "b: tensor([[ 0.7321,  0.5893, -0.5360,  0.2156],\n",
      "        [ 0.1993,  2.3670, -0.1326, -0.5050],\n",
      "        [-0.4142, -0.5313, -0.9406,  0.2467]])\n",
      "c: Tensor(shape=[3, 1], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "x: Tensor(shape=[3, 1], dtype=float64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import paddle\n",
    "\n",
    "device = \"cuda\"\n",
    "paddle.set_device(\"gpu\" if device == \"cuda\" else \"cpu\")\n",
    "\n",
    "paddle.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "a = torch.randn(3)\n",
    "b = torch.randn(3, 4)\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)\n",
    "\n",
    "\n",
    "c = paddle.randn((3, 1))\n",
    "print(\"c:\", c)\n",
    "\n",
    "d = paddle.randn((3, 1), dtype=\"float64\")\n",
    "print(\"x:\", d)\n",
    "# x: [[-0.32342386 -1.200079  ]\n",
    "#     [ 0.7979031  -0.90978354]\n",
    "#     [ 0.40597573  1.8095392 ]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
